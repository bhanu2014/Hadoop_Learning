package com.spark.streaming;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.streaming.Duration;
import org.apache.spark.streaming.api.java.JavaDStream;
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream;
import org.apache.spark.streaming.api.java.JavaStreamingContext;

public class LogAnalyzerStreamingSQL {
	  private static final Duration WINDOW_LENGTH = new Duration(30 * 1000);
	  // Stats will be computed every slide interval time.
	  private static final Duration SLIDE_INTERVAL = new Duration(10 * 1000);
	@SuppressWarnings("resource")
	public static void main(String[] args){
		SparkConf conf=new SparkConf().setAppName("Spark Streaming learning").setMaster("local");
		JavaSparkContext spctx=new JavaSparkContext(conf);
		JavaStreamingContext jssc=new JavaStreamingContext(spctx,SLIDE_INTERVAL);
		JavaReceiverInputDStream<String> logDataStream=jssc.socketTextStream("localhost",9999);
		JavaDStream<CountryBean> accesslogDstream=logDataStream.map(CountryBean::parseStreamLine);
		JavaDStream<CountryBean> windowDstream=accesslogDstream.window(WINDOW_LENGTH,SLIDE_INTERVAL);
		
		windowDstream.foreach(accesslogs ->{
			if(accesslogs.count()==0){
				System.out.println("No acesslogs in this interval");
			}
			else{
				System.out.println("its working: Count:"+accesslogs.count());
			}
			
			
			return null;
		});
		jssc.start();
		jssc.awaitTermination();
	}
}
