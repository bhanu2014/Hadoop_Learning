package com.spark.hbase;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.KeyValue;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.mapred.TableInputFormat;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.Function;

import java.util.Iterator;

import com.cloudera.spark.hbase.JavaHBaseContext;

public class SparkHbaseBulkGet {
	public static void  main(String[] args){
		SparkConf conf=new SparkConf().setAppName("Spark with hbase bulk get").setMaster("local[4]");
		JavaSparkContext ctx=new JavaSparkContext(conf);
		Configuration hconf=HBaseConfiguration.create();
		JavaHBaseContext hctx=new JavaHBaseContext(ctx, hconf);
		hconf.addResource(new Path("/etc/hbase/conf.cloudera.yarn/core-site.xml"));
		hconf.addResource(new Path("/etc/hbase/conf.cloudera.hbase/hbase-site.xml"));
		hconf.set(TableInputFormat.INPUT_TABLR,"countryLog" );
	
		JavaRDD<String> rdd=null;

	
	}
	
}