package com.bimarianDev.truckDataIngestion;

import java.io.FileNotFoundException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.Function;

import com.cloudera.spark.hbase.JavaHBaseContext;
//import com.spark.hbase.SparkHbaseBulkInsert.PutFunction;
import com.google.gson.JsonIOException;
import com.google.gson.JsonSyntaxException;

public class TruckDataBulkInsert {
	@SuppressWarnings({"unused" })
	public static void main(String[] args) throws JsonIOException, JsonSyntaxException, FileNotFoundException{
		SparkConf conf=new SparkConf().setAppName("Truck Data Bulk Insert").setMaster("local[2]");
		JavaSparkContext ctx=new JavaSparkContext(conf);
		
		//JavaRDD<String> truckData=ctx.textFile("hdfs://hadoop1.test.com/user/root/bhanu/countryLog.txt");
		JavaRDD<TruckBean> truckinnfo=TruckJsonToObject.getTruckData("C:/Users/Vostro/Desktop/input/employee.json");
		
		System.out.println("log data count"+truckinnfo.count());

		
	
		Configuration hconf = HBaseConfiguration.create();
		hconf.addResource(new Path("/etc/hbase/conf.cloudera.yarn/core-site.xml"));
		hconf.addResource(new Path("/etc/hbase/conf.cloudera.hbase/hbase-site.xml"));
		
		JavaHBaseContext hbaseContext =new JavaHBaseContext(ctx,hconf);
		
		hbaseContext.bulkPut(truckData,"truckInfo",new PutFunction(), true);
		}
		@SuppressWarnings("serial")
		public static class PutFunction implements Function<String, Put>{
			@Override
			public Put call(String logline) throws Exception {
				String[] cell=logline.split(",");
				 Put put = new Put(Bytes.toBytes(System.currentTimeMillis()));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("VNo")),(Bytes.toBytes( cell[0])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("groupId")),(Bytes.toBytes( cell[1])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("deploymentId")),(Bytes.toBytes( cell[2])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Time")),(Bytes.toBytes( cell[3])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Acc")),(Bytes.toBytes( cell[4])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Lat")),(Bytes.toBytes( cell[5])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Lon")),(Bytes.toBytes( cell[6])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Speed")),(Bytes.toBytes( cell[7])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Angle")),(Bytes.toBytes( cell[8])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Locate")),(Bytes.toBytes( cell[9])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Oil")),(Bytes.toBytes( cell[10])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Weight")),(Bytes.toBytes( cell[11])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Mile")),(Bytes.toBytes( cell[12])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("version")),(Bytes.toBytes( cell[13])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("timestamp")),(Bytes.toBytes( cell[14])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Location[0]")),(Bytes.toBytes( cell[15])));
				 put.add((Bytes.toBytes("truckParameters")),(Bytes.toBytes("Location[1]")),(Bytes.toBytes( cell[16])));
				 
				return put;
			}
			
		}
}
